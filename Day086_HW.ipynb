{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 試比較 save_best_only 與否的差異\n",
    "2. 請僅存入將 save_weights_only 設定為 True, 並嘗試 reset ipynb 並將模型與權重重新建回並預測 x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_mlp():\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    return model\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "\n",
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Code Here\\n撰寫你的訓練流程並將結果用 dictionary 紀錄\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入 Callbacks\n",
    "\"\"\"Code Here\n",
    "設定 callbacks: model checkpoint\n",
    "\"\"\"\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath=\"./tmp.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=True)\n",
    "model_ckpt2 = ModelCheckpoint(filepath=\"./tmp2.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=True)\n",
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0723 23:26:59.049597 139620787275584 deprecation_wrapper.py:119] From /home/jianhao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0723 23:26:59.060215 139620787275584 deprecation_wrapper.py:119] From /home/jianhao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0723 23:26:59.061847 139620787275584 deprecation_wrapper.py:119] From /home/jianhao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0723 23:26:59.107841 139620787275584 deprecation_wrapper.py:119] From /home/jianhao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0723 23:26:59.269153 139620787275584 deprecation_wrapper.py:119] From /home/jianhao/opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0723 23:26:59.274371 139620787275584 deprecation_wrapper.py:119] From /home/jianhao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0723 23:26:59.327641 139620787275584 deprecation.py:323] From /home/jianhao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.2199 - acc: 0.2658 - val_loss: 2.0984 - val_acc: 0.3302\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.7399 - acc: 0.3938 - val_loss: 1.8295 - val_acc: 0.3798\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.6183 - acc: 0.4336 - val_loss: 1.7022 - val_acc: 0.4149\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.5470 - acc: 0.4571 - val_loss: 1.6494 - val_acc: 0.4320\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.4924 - acc: 0.4775 - val_loss: 1.6159 - val_acc: 0.4407\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.4461 - acc: 0.4944 - val_loss: 1.5776 - val_acc: 0.4459\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 1.4076 - acc: 0.5080 - val_loss: 1.5525 - val_acc: 0.4576\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.3726 - acc: 0.5204 - val_loss: 1.5326 - val_acc: 0.4645\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 1.3401 - acc: 0.5328 - val_loss: 1.5239 - val_acc: 0.4720\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.3111 - acc: 0.5443 - val_loss: 1.5080 - val_acc: 0.4739\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 1.2822 - acc: 0.5556 - val_loss: 1.5110 - val_acc: 0.4701\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.2565 - acc: 0.5637 - val_loss: 1.4928 - val_acc: 0.4765\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 1.2312 - acc: 0.5717 - val_loss: 1.4884 - val_acc: 0.4807\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.2054 - acc: 0.5829 - val_loss: 1.4745 - val_acc: 0.4793\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.1832 - acc: 0.5908 - val_loss: 1.4777 - val_acc: 0.4833\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 1.1592 - acc: 0.6006 - val_loss: 1.4722 - val_acc: 0.4815\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.1341 - acc: 0.6113 - val_loss: 1.4729 - val_acc: 0.4786\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.1118 - acc: 0.6199 - val_loss: 1.4738 - val_acc: 0.4887\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.0917 - acc: 0.6268 - val_loss: 1.4657 - val_acc: 0.4900\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.0710 - acc: 0.6361 - val_loss: 1.4581 - val_acc: 0.4929\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 1.0494 - acc: 0.6440 - val_loss: 1.4616 - val_acc: 0.4960\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 1.0279 - acc: 0.6516 - val_loss: 1.4608 - val_acc: 0.4933\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 1.0078 - acc: 0.6605 - val_loss: 1.4636 - val_acc: 0.4936\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.9853 - acc: 0.6680 - val_loss: 1.4726 - val_acc: 0.4935\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.9652 - acc: 0.6754 - val_loss: 1.4778 - val_acc: 0.4924\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.9459 - acc: 0.6822 - val_loss: 1.4775 - val_acc: 0.4896\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.9273 - acc: 0.6881 - val_loss: 1.4780 - val_acc: 0.4918\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.9064 - acc: 0.6983 - val_loss: 1.4894 - val_acc: 0.4939\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.8879 - acc: 0.7039 - val_loss: 1.4917 - val_acc: 0.4917\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.8700 - acc: 0.7110 - val_loss: 1.4858 - val_acc: 0.5001\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.8504 - acc: 0.7208 - val_loss: 1.4958 - val_acc: 0.4982\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.8288 - acc: 0.7288 - val_loss: 1.4869 - val_acc: 0.4967\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.8111 - acc: 0.7354 - val_loss: 1.4971 - val_acc: 0.4954\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.7917 - acc: 0.7428 - val_loss: 1.5117 - val_acc: 0.4952\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.7717 - acc: 0.7527 - val_loss: 1.5326 - val_acc: 0.4965\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.7553 - acc: 0.7587 - val_loss: 1.5253 - val_acc: 0.4962\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.7356 - acc: 0.7663 - val_loss: 1.5309 - val_acc: 0.4910\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.7170 - acc: 0.7737 - val_loss: 1.5559 - val_acc: 0.4935\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.6994 - acc: 0.7795 - val_loss: 1.5566 - val_acc: 0.4945\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.6799 - acc: 0.7889 - val_loss: 1.5547 - val_acc: 0.4950\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.6614 - acc: 0.7952 - val_loss: 1.5824 - val_acc: 0.4846\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.6447 - acc: 0.8030 - val_loss: 1.5705 - val_acc: 0.4997\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.6285 - acc: 0.8097 - val_loss: 1.5825 - val_acc: 0.4943\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.6109 - acc: 0.8147 - val_loss: 1.6072 - val_acc: 0.4932\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.5931 - acc: 0.8225 - val_loss: 1.6107 - val_acc: 0.4898\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.5748 - acc: 0.8299 - val_loss: 1.6167 - val_acc: 0.4891\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5582 - acc: 0.8371 - val_loss: 1.6320 - val_acc: 0.4950\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.5426 - acc: 0.8444 - val_loss: 1.6559 - val_acc: 0.4956\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.5258 - acc: 0.8492 - val_loss: 1.6700 - val_acc: 0.4901\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.5110 - acc: 0.8551 - val_loss: 1.6996 - val_acc: 0.4888\n",
      "10000/10000 [==============================] - 1s 106us/step\n"
     ]
    }
   ],
   "source": [
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[model_ckpt]\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "# Load back\n",
    "model = keras.models.load_model(\"./tmp.h5\")\n",
    "loss_loadback, acc_loadback = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 2.2676 - acc: 0.2639 - val_loss: 2.0430 - val_acc: 0.3288\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.7577 - acc: 0.3887 - val_loss: 1.8402 - val_acc: 0.3709\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6259 - acc: 0.4314 - val_loss: 1.6997 - val_acc: 0.4081\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.5511 - acc: 0.4590 - val_loss: 1.6353 - val_acc: 0.4316\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.4958 - acc: 0.4783 - val_loss: 1.5853 - val_acc: 0.4431\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.4509 - acc: 0.4956 - val_loss: 1.5592 - val_acc: 0.4550\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.4129 - acc: 0.5094 - val_loss: 1.5319 - val_acc: 0.4630\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.3776 - acc: 0.5195 - val_loss: 1.5181 - val_acc: 0.4663\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.3464 - acc: 0.5305 - val_loss: 1.5185 - val_acc: 0.4681\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3156 - acc: 0.5432 - val_loss: 1.4962 - val_acc: 0.4779\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.2884 - acc: 0.5514 - val_loss: 1.4831 - val_acc: 0.4806\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.2618 - acc: 0.5604 - val_loss: 1.4856 - val_acc: 0.4833\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.2360 - acc: 0.5715 - val_loss: 1.4851 - val_acc: 0.4804\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.2126 - acc: 0.5783 - val_loss: 1.4836 - val_acc: 0.4826\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.1877 - acc: 0.5892 - val_loss: 1.4657 - val_acc: 0.4837\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.1650 - acc: 0.5984 - val_loss: 1.4668 - val_acc: 0.4880\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.1426 - acc: 0.6066 - val_loss: 1.4640 - val_acc: 0.4923\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.1205 - acc: 0.6136 - val_loss: 1.4590 - val_acc: 0.4875\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.0985 - acc: 0.6223 - val_loss: 1.4559 - val_acc: 0.4924\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.0750 - acc: 0.6308 - val_loss: 1.4604 - val_acc: 0.4887\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.0552 - acc: 0.6404 - val_loss: 1.4566 - val_acc: 0.4957\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.0350 - acc: 0.6468 - val_loss: 1.4582 - val_acc: 0.4970\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.0147 - acc: 0.6531 - val_loss: 1.4595 - val_acc: 0.4923\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9919 - acc: 0.6643 - val_loss: 1.4503 - val_acc: 0.4997\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.9738 - acc: 0.6708 - val_loss: 1.4781 - val_acc: 0.4942\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9546 - acc: 0.6772 - val_loss: 1.4606 - val_acc: 0.4992\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9334 - acc: 0.6861 - val_loss: 1.4684 - val_acc: 0.4970\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9110 - acc: 0.6943 - val_loss: 1.4788 - val_acc: 0.4959\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.8929 - acc: 0.7039 - val_loss: 1.4832 - val_acc: 0.4988\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.8747 - acc: 0.7090 - val_loss: 1.4805 - val_acc: 0.4975\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.8539 - acc: 0.7171 - val_loss: 1.4830 - val_acc: 0.5010\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.8348 - acc: 0.7241 - val_loss: 1.4885 - val_acc: 0.5033\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.8164 - acc: 0.7322 - val_loss: 1.4936 - val_acc: 0.4998\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.7954 - acc: 0.7414 - val_loss: 1.4989 - val_acc: 0.4993\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.7777 - acc: 0.7476 - val_loss: 1.5123 - val_acc: 0.5001\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.7592 - acc: 0.7553 - val_loss: 1.5178 - val_acc: 0.4978\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.7390 - acc: 0.7641 - val_loss: 1.5283 - val_acc: 0.4972\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.7209 - acc: 0.7714 - val_loss: 1.5256 - val_acc: 0.5018\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.7041 - acc: 0.7767 - val_loss: 1.5290 - val_acc: 0.5038\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.6840 - acc: 0.7860 - val_loss: 1.5610 - val_acc: 0.5004\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.6680 - acc: 0.7924 - val_loss: 1.5631 - val_acc: 0.4955\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.6491 - acc: 0.8001 - val_loss: 1.5717 - val_acc: 0.4993\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.6304 - acc: 0.8076 - val_loss: 1.5780 - val_acc: 0.4986\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.6145 - acc: 0.8143 - val_loss: 1.5905 - val_acc: 0.4949\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.5994 - acc: 0.8186 - val_loss: 1.6045 - val_acc: 0.4956\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.5817 - acc: 0.8256 - val_loss: 1.6250 - val_acc: 0.4954\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.5639 - acc: 0.8326 - val_loss: 1.6291 - val_acc: 0.4949\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.5469 - acc: 0.8431 - val_loss: 1.6342 - val_acc: 0.4975\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.5305 - acc: 0.8480 - val_loss: 1.6496 - val_acc: 0.4983\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.5135 - acc: 0.8524 - val_loss: 1.6706 - val_acc: 0.4951\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "\n",
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[model_ckpt]\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 138us/step\n"
     ]
    }
   ],
   "source": [
    "# Load back\n",
    "model2 = keras.models.load_model(\"./tmp.h5\")\n",
    "loss_loadback, acc_loadback = model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VGX6//H3nUYSIIEk1BQSek0ChC5NilhAFFRQQXEV17quul/d1Z+yuq6u3XUti4oIFkQsgIoFpai0BEQ6hJKQEEglIb3MPL8/zsAGCCRIwmQm9+u65po5c545c59k8pmT5zznHDHGoJRSyr14OLsApZRStU/DXSml3JCGu1JKuSENd6WUckMa7kop5YY03JVSyg1puCullBvScFcuR0RWishREWnk7FqUqq803JVLEZFIYChggAkX8H29LtR7KVUbNNyVq5kOrAPmAjcdf1JE/ETkBRFJFpE8EflZRPwc8y4SkTUikisiKSJys+P5lSJya6Vl3CwiP1eaNiJyl4gkAomO515xLOOYiGwUkaGV2nuKyN9EZJ+I5Dvmh4vIayLyQuWVEJGlInJfXfyAlAINd+V6pgMfOG6XiEgrx/PPA32BwUAQ8H+AXUQigGXAq0ALIBbYfA7vNxEYAHR3TMc7lhEEfAh8IiK+jnn3A1OBy4AA4BagCHgPmCoiHgAiEgKMAj46lxVX6lxouCuXISIXAe2AhcaYjcA+4HpHaN4C/MkYc8gYYzPGrDHGlAI3AMuNMR8ZY8qNMdnGmHMJ96eNMTnGmGIAY8z7jmVUGGNeABoBXRxtbwUeNcbsNpbfHG03AHlYgQ4wBVhpjEk/zx+JUmek4a5cyU3Ad8aYLMf0h47nQgBfrLA/VfgZnq+plMoTIvKAiOx0dP3kAoGO96/uvd4DbnQ8vhGYfx41KVUt3UmkXIKj//xawFNEjjiebgQ0A9oAJUAH4LdTXpoC9D/DYgsB/0rTratoc+K0qY7+9YewtsC3G2PsInIUkErv1QHYVsVy3ge2iUgM0A344gw1KVUrdMtduYqJgA2r7zvWcesG/ITVDz8HeFFE2jp2bA5yDJX8ABgtIteKiJeIBItIrGOZm4GrRcRfRDoCf6imhqZABZAJeInIY1h968e9DTwpIp3EEi0iwQDGmFSs/vr5wKfHu3mUqisa7spV3AS8a4w5aIw5cvwG/AerX/1hYCtWgOYA/wI8jDEHsXZwPuB4fjMQ41jmS0AZkI7VbfJBNTV8i7Vzdg+QjPXfQuVumxeBhcB3wDHgHcCv0vz3gF5ol4y6AEQv1qHUhSEiw7C6ZyKNMXZn16Pcm265K3UBiIg38CfgbQ12dSFouCtVx0SkG5CLteP3ZSeXoxoI7ZZRSik3pFvuSinlhpw2zj0kJMRERkY66+2VUsolbdy4McsY06K6dk4L98jISBISEpz19kop5ZJEJLkm7bRbRiml3JCGu1JKuSENd6WUckP16sRh5eXlpKamUlJS4uxSVDV8fX0JCwvD29vb2aUopapQr8I9NTWVpk2bEhkZiYhU/wLlFMYYsrOzSU1NJSoqytnlKKWqUK+6ZUpKSggODtZgr+dEhODgYP0PS6l6rF6FO6DB7iL096RU/Vbvwl0ppVxZUVkFPyVm8vy3uzmYXeS0OupVn7uz5ebm8uGHH3LnnXee82svu+wyPvzwQ5o1a1YHlSml6qv8knISko+yfn8O6w9kszU1jwq7wdND6N42gIhg/+oXUgc03CvJzc3l9ddfrzLcbTYbnp6eZ3zt119/XZel/W7GGIwxeHjoP2lK1YYKm53NKbn8lJjFT4mZ/Jaah81u8PIQosMCmTmsPQPaB9O3XXOaNHJexOpffCUPP/ww+/btIzY2lr/85S+sXLmSkSNHcv3119OrVy8AJk6cSN++fenRowezZ88+8drIyEiysrJISkqiW7du3HbbbfTo0YOxY8dSXHz6FdWWLl3KgAED6N27N6NHjyY9PR2AgoICZsyYQa9evYiOjubTTz8F4JtvvqFPnz7ExMQwatQoAGbNmsXzzz9/Ypk9e/YkKSnpRA133nknffr0ISUlhTvuuIO4uDh69OjB448/fuI18fHxDB48mJiYGPr3709+fj5Dhw5l8+bNJ9oMGTKELVu21OJPWinXkl9Szvx1ycycl0DvJ75n8ptrefXHRGwG/ji8Pe//YQBbZo3lszuH8H/jujK8cwunBjvU4y33vy/dzo60Y7W6zO5tA3h8fI8zzn/mmWfYtm3biWBbuXIlGzZsYNu2bSeG/M2ZM4egoCCKi4vp168fkyZNIjg4+KTlJCYm8tFHH/HWW29x7bXX8umnn3LjjTee1Oaiiy5i3bp1iAhvv/02zz77LC+88AJPPvkkgYGBbN26FYCjR4+SmZnJbbfdxurVq4mKiiInJ6fadd29ezfvvvsur7/+OgBPPfUUQUFB2Gw2Ro0axZYtW+jatSvXXXcdH3/8Mf369ePYsWP4+flx6623MnfuXF5++WX27NlDaWkp0dHRNf9BK+Um7HbDoo2pPPvtbrIKSglr7scVMW0Z2imEwR2Caebv4+wSz6jehnt90b9//5PGcv/73//m888/ByAlJYXExMTTwj0qKorYWOsazH379iUpKem05aampnLddddx+PBhysrKTrzH8uXLWbBgwYl2zZs3Z+nSpQwbNuxEm6CgoGrrbteuHQMHDjwxvXDhQmbPnk1FRQWHDx9mx44diAht2rShX79+AAQEWNd6vuaaa3jyySd57rnnmDNnDjfffHO176eUu4lPyuHvS7ez7dAx+kQ0463pfYkNb+YyI8XqbbifbQv7QmrcuPGJxytXrmT58uWsXbsWf39/RowYUeVY70aNGp147OnpWWW3zD333MP999/PhAkTWLlyJbNmzQKsPvJTPzxVPQfg5eWF3f6/K7ZVrqVy3QcOHOD5558nPj6e5s2bc/PNN1NSUnLG5fr7+zNmzBgWL17MwoUL9eydqkE5lFvM01/v5Msth2kT6MsrU2KZENPWZUL9OO1zr6Rp06bk5+efcX5eXh7NmzfH39+fXbt2sW7dut/9Xnl5eYSGhgLw3nvvnXh+7Nix/Oc//zkxffToUQYNGsSqVas4cOAAwIlumcjISDZt2gTApk2bTsw/1bFjx2jcuDGBgYGkp6ezbNkyALp27UpaWhrx8fEA5OfnU1FRAcCtt97KvffeS79+/Wr0n4JSrswYw28pufzt861c/PxKvt+Rzr2jOvHDA8O5MjbU5YId6vGWuzMEBwczZMgQevbsyaWXXsrll19+0vxx48bx5ptvEh0dTZcuXU7q9jhXs2bN4pprriE0NJSBAweeCOZHH32Uu+66i549e+Lp6cnjjz/O1VdfzezZs7n66qux2+20bNmS77//nkmTJjFv3jxiY2Pp168fnTt3rvK9YmJi6N27Nz169KB9+/YMGTIEAB8fHz7++GPuueceiouL8fPzY/ny5TRp0oS+ffsSEBDAjBkzfvc6KlXfHS0s4/NfD7EwIYVdR/Lx9fZgfExb/jymM6HN/Jxd3nlx2jVU4+LizKn/7u/cuZNu3bo5pR51srS0NEaMGMGuXbvOOIxSf1/KFdnthl/2ZbEgPoXvt6dTZrMTHRbItXHhTIhtS4Bv/T4ZnohsNMbEVddOt9zVaebNm8cjjzzCiy++qOPjldtIyy3mk4RUFiakcCi3mGb+3lw/IILr+oXTrU2As8urdRru6jTTp09n+vTpzi5DqfNWUm5jxa4MFsSnsDoxE2Pgoo4hPHxpV8Z0b4Wv95kPTHR1Gu5KKbdxtLCMjclHiU/OYWPSUbak5lFms9Mm0Jd7RnbkmrhwwoOcczqAC03DXSnl0nakHeOzTams2pNJYkYBAN6eQq/QQGYMiWRIxxCGdAzB08P1RrycDw13pZTLycgvYfGvaXy6KZVdR/Lx9hQGdwhhYu9Q+kUGER0W6NZdLjWh4a6UcgnlNjvfbU/nk40prN6Tid1AbHgznryyB1dEt6V54/p7KgBnqNFQCBEZJyK7RWSviDxcxfwIEVkhIr+KyBYRuaz2S62fmjRpAlhDBydPnlxlmxEjRuhRnkr9TkfySnjp+z0MeeZH7vpwE3uO5HPHiA4sv384X9w1hGmDIjXYq1DtlruIeAKvAWOAVCBeRJYYY3ZUavYosNAY84aIdAe+BiLroN56q23btixatMjZZVSpoqICLy/9J025DmMMa/dn8/66ZL7dno7dGEZ0bsEzg9oxvHPLBtd//nvUZMu9P7DXGLPfGFMGLACuPKWNAY4PFA0E0mqvxAvnoYceOnEWRbCOIn3hhRcoKChg1KhR9OnTh169erF48eLTXpuUlETPnj0BKC4uZsqUKURHR3PddddVeW4ZgCeeeIJ+/frRs2dPZs6cyfEDyvbu3cvo0aOJiYmhT58+7Nu3D4Bnn32WXr16ERMTw8MPW/9AVf6vICsri8jISADmzp3LNddcw/jx4xk7duxZ12HevHlER0cTExPDtGnTyM/PJyoqivLycsA6fUFkZOSJaaXqSmFpBfPXJTP2pdVc/9Z61uzL5taLolj54AjendGfi7u20mCvoZpszoUCKZWmU4EBp7SZBXwnIvcAjYHRVS1IRGYCMwEiIiLO/q7LHoYjW2tQ3jlo3QsufeaMs6dMmcJ999134mIdCxcu5JtvvsHX15fPP/+cgIAAsrKyGDhwIBMmTDjj+SbeeOMN/P392bJlC1u2bKFPnz5Vtrv77rt57LHHAJg2bRpffvkl48eP54YbbuDhhx/mqquuoqSkBLvdzrJly/jiiy9Yv349/v7+NTrt79q1a9myZQtBQUFUVFRUuQ47duzgqaee4pdffiEkJIScnByaNm3KiBEj+Oqrr5g4cSILFixg0qRJeHvX7yP3lOs6kFXIvLVJLEpIJb+0gl6hgTw3OZrxMW0b/I7R36sm4V5Vgp16zoKpwFxjzAsiMgiYLyI9jTH2k15kzGxgNlinH/g9Bdel3r17k5GRQVpaGpmZmTRv3pyIiAjKy8v529/+xurVq/Hw8ODQoUOkp6fTunXrKpezevVq7r33XgCio6PPeC70FStW8Oyzz1JUVEROTg49evRgxIgRHDp0iKuuugoAX19fwDoV8IwZM/D3t8bo1uRkXmPGjDnRzhhT5Tr8+OOPTJ48mZCQkJOWe+utt/Lss88yceJE3n33Xd56662a/hiVqpFym53VezKZtzaZVXsy8fYULuvVhpsGR9LbhU6tW1/VJNxTgfBK02Gc3u3yB2AcgDFmrYj4AiFAxu+u7Cxb2HVp8uTJLFq0iCNHjjBlyhQAPvjgAzIzM9m4cSPe3t5ERkZWearfyqr7YJaUlHDnnXeSkJBAeHg4s2bNOnEa3qrU5LS/p9ZU+bS/Z1qHMy13yJAhJCUlsWrVKmw224kuJ6XOhzGGTQePsnhzGl9uOUxOYRktmzbiz6M7M3VAOC2b+jq7RLdRkz73eKCTiESJiA8wBVhySpuDwCgAEekG+AKZtVnohTJlyhQWLFjAokWLTox+ycvLo2XLlnh7e7NixQqSk5PPuoxhw4bxwQcfALBt27YqL1F3PIhDQkIoKCg4sTM2ICCAsLAwvvjiCwBKS0spKipi7NixzJkzh6Ii62rqlU/7u3HjRoCz7tA90zqMGjWKhQsXkp2dfdJywToNwdSpU/XMkOq87c0o4PlvdzPsuRVMemMtH8enMLhDMG9Nj+Pnhy7mT6M7abDXsmq33I0xFSJyN/At4AnMMcZsF5EngARjzBLgAeAtEfkzVpfNzcZZp5s8Tz169CA/P5/Q0FDatGkDwA033MD48eOJi4sjNjaWrl27nnUZd9xxBzNmzCA6OprY2Fj69+9/WptmzZpx22230atXLyIjI09cDQlg/vz53H777Tz22GN4e3vzySefMG7cODZv3kxcXBw+Pj5cdtll/POf/+TBBx/k2muvZf78+Vx88cVnrOlM69CjRw8eeeQRhg8fjqenJ71792bu3LknXvPoo48yderUc/0xKgVAYno+Ly3fw9dbj+AhcFGnFtw3qjOX9Gzt9GuMujs95a86o0WLFrF48WLmz59f5Xz9fakzOZBVyCvL97D4tzQa+3hxy5BIpg2KpEXTRtW/WJ2VnvJXnZd77rmHZcuW8fXXXzu7FOVCUnKKePXHRD7ddAhvT+H2YR24fVh7PcjICTTcVZVeffVVZ5egXIAxhu1px1i5O4Mfd2WwOSUXL08PbhoUyR0jOuiWuhPVu3A/0+gNVb+46C4VVQtKK2ys3J3Jil0ZrNidQfqxUgCiwwK5++JOTO0fTptA175EnTuoV+Hu6+tLdnY2wcHBGvD1mDGG7OzsE2PwVcNwMLuIDzcc5JOEFLILy2jayIuhnUMY2aUlw7u00NEu9Uy9CvewsDBSU1PJzHTJUZQNiq+vL2FhYc4uQ9WxCpud5Tsz+GB9Mj8lZuHpIYzq2pKpAyK4qGMI3p56Gcb6ql6Fu7e3N1FRUc4uQ6kGr7C0gg/WJ/POzwdIP1ZKm0Bf/jy6M9f1C6d1oG6hu4J6Fe5KKefKKy5n3pok3vnlALlF5VzUMYSnJvZiRJcWeOlWukvRcFdKkVNYxru/HGDuL0nkl1YwultL7hrZkd4RzZ1dmvqdNNyVasD2ZhQwf20Sn2xMpbjcxqU9W3PXyI70aBvo7NLUedJwV6qBsdkNP+xMZ97aZH7em4WPpwdXxLThjuEd6NSqqbPLU7VEw12pBiIjv4RPNx7i/XXJHMotpm2gL3+5pAtT+oUT3EQPNnI3Gu5KubGcwjK+2XaEpb+lse5ANsbA4A7B/L8rujO6W0vdSerGNNyVcjOFpRUs23aEL7ek8XNiFhV2Q/uQxtxzcScmxLSlY8smzi5RXQAa7kq5ieIyG/PXJfHmqv3kFJYR2syPW4e2Z3xMG7q3CdCjvhsYDXelXFxJuY0P1h/kjZX7yCooZVjnFtw9siP9IptroDdgGu5KuajSChsLNqTw2oq9ZOSXMrhDMG/e2Ie4yOqvr6vcn4a7Ui4mp7CMD9Yl897aZLIKSukfGcQrU3ozqEOws0tT9YiGu1IuYm9GPu/8nMRnm1IprbAzvHMLZg5rz+AOehZVdToNd6XqMZvd8PPeLOb+coAVuzNp5OXB1X1CuWVIlB5wpM5Kw12peiglp4hPNqayKCGFtLwSQpo04v4xnblhQIQecKRqRMNdqXqipNzGdzvSWRifwi/7sgAY2qkFj1zendHdW9LIy9PJFSpXouGulJNlFZQyf20y769LJtsxPv2+UZ2ZHBdGaDO9XJ36fTTclXKSfZkFvP3TAT7dlEpZhZ1RXVty0+BILuoYgoeH7iBV50fDXakLqLTCxvr9Ocxbm8TynRn4eHkwqU8of7goio4tdQepqj01CncRGQe8AngCbxtjnjll/kvASMekP9DSGNOsNgtVylUlZxeyak8mq/dksmZfNkVlNoIa+/CnUZ2YNqgdIbqDVNWBasNdRDyB14AxQCoQLyJLjDE7jrcxxvy5Uvt7gN51UKtSLiPjWAlv/bSf73ekk5RdBEBEkD+T+oQxvHMLLuoUgq+37iBVdacmW+79gb3GmP0AIrIAuBLYcYb2U4HHa6c8pVxLXlE5b67ex7u/HKDCZhjaKYQZQ6IY3rkFkSGNnV2eakBqEu6hQEql6VRgQFUNRaQdEAX8eIb5M4GZABEREedUqFL1WXGZjXfXHODNlfvIL63gypi2/HlMZ9oFa6Ar56hJuFe1296coe0UYJExxlbVTGPMbGA2QFxc3JmWoZTLKCm38cnGVF79IZGM/FJGdW3Jg5d0oVubAGeXphq4moR7KhBeaToMSDtD2ynAXedblFL1XU5hGe+vS2be2iSyCsroF9mc127oQz89I6OqJ2oS7vFAJxGJAg5hBfj1pzYSkS5Ac2BtrVaoVD2SlFXIOz8f4JONKZSU2xnZpQW3DW3PID15l6pnqg13Y0yFiNwNfIs1FHKOMWa7iDwBJBhjljiaTgUWGGO0u0W5na2pefxnRSLf7UjH28ODib3bcuvQ9nTWk3epekqclcVxcXEmISHBKe+tVE1tTD7Kqz8msnJ3JgG+XkwfFMn0we1o2dTX2aWpBkpENhpj4qprp0eoKlWFdfuzefXHRH7Zm01QYx/+ckkXpg9qR1Nfb2eXplSNaLgr5VBYWsF3O47w0foUNiTlENKkEY9c1o0bBkbg76N/Ksq16CdWNWjlNjs/J2bxxeZDfLc9neJyG6HN/Hh8fHem9o/Qo0iVy9JwVw2OMYZfU3JZ/OshvtxymOzCMgL9vLmqTygTY0OJa9dcz8qoXJ6Gu2ow9mUWsPjXQyz+LY3k7CJ8vDwY060VV8a2ZUSXlvh4eTi7RKVqjYa7cmvHSsr5JCGVxZsPsSU1DxEY3CGYu0Z2ZFzP1gToDlLlpjTclVsyxvDllsM88eUOMvNL6RkawKOXd2N8TFtaBegwRuX+NNyV20nOLuT/Ld7O6j2Z9AwN4K3pccSG6+UFVMOi4a7cRmmFjdmr9vOfFXvx9vRg1vjuTBsUiafuHFUNkIa7cnmFpRV8vyOdV39MZF9mIZdHt+GxK7pr94tq0DTclUsqKbexcncmS39L44dd6ZSU24kM9mfujH6M6NLS2eUp5XQa7splVNjs/LIvm8WOA44KSisIbuzDNX3DmRDblr4ROj5dqeM03FW9Zozht9Q8vvj1EF9uSSOroIymvl5c2rM142PaMrhDMF6eOj5dqVNpuKt66VBuMZ8kpLB4cxoHsgrx8fTg4q4tmdjbOuBITwug1NlpuKt6JTO/lP/8mMiHGw5SYTcMjArmj8PbM65nGwL99IAjpWpKw13VC3nF5cxevY85PydRZrNzbVw4d1/ckdBmfs4uTSmXpOGunKq4zMbcNUm8uWofecXljI9py/1jOhMV0tjZpSnl0jTclVMcKynn/XXJzPk5iayCUkZ0acGDY7vQMzTQ2aUp5RY03NUFlZlfypxfDvD+2mTySysY1rkFd4/sSP+oIGeXppRb0XBXF0RKThGzV+9nYUIKZTY7l/Vswx0jOuiWulJ1RMNd1am9Gfm8vmIfi39Lw0NgUp8wbh/eQfvUlapjGu6qTmw7lMdrK/byzfYj+Hp5cvPgSG4b2p7WgXq+F6UuBA13VWuMMWw4kMMbq/axcncmTX29uGtER2YMiSS4SSNnl6dUg6Lhrs5bZn4pn21KZWFCCvsyCwlq7MNfLunCtEHt9EpHSjmJhrv6XSpsdlYnZvJxfAo/7Mygwm7o2645z07qwBUxbfD30Y+WUs5Uo79AERkHvAJ4Am8bY56pos21wCzAAL8ZY66vxTpVPZFXXM5HGw7y3pokDueVENLEh1suiuLauDA6tmzq7PKUUg7VhruIeAKvAWOAVCBeRJYYY3ZUatMJ+CswxBhzVET0hNpuJvVoEe/+ksSCDQcpLLMxuEMwj4/vwahuLfHWszIqVe/UZMu9P7DXGLMfQEQWAFcCOyq1uQ14zRhzFMAYk1HbhSrn2HYoj9mr9/PV1sMIcEV0G24d2l7HpytVz9Uk3EOBlErTqcCAU9p0BhCRX7C6bmYZY745dUEiMhOYCRAREfF76lUXyJbUXF76fg8rdmfSpJEXf7goipsHR9JWT+SllEuoSbhXdWkbU8VyOgEjgDDgJxHpaYzJPelFxswGZgPExcWdugxVD2w7lMfLy/ewfGcGzfy9ddSLUi6qJuGeCoRXmg4D0qpos84YUw4cEJHdWGEfXytVqjq3I+0YLy/fw3c70gnw9eKBMZ25eUgkTTXUlXJJNQn3eKCTiEQBh4ApwKkjYb4ApgJzRSQEq5tmf20WqupGdkEp//pmFwsTUmnq68V9oztxy0VRuqWulIurNtyNMRUicjfwLVZ/+hxjzHYReQJIMMYsccwbKyI7ABvwF2NMdl0Wrs6PzW74cMNBnvtmF0VlNmYOa89dIzoS6K+hrpQ7EGOc0/UdFxdnEhISnPLeDd2mg0d5bPE2th06xqD2wTxxZQ86tdIx6kq5AhHZaIyJq66dHkbYgOzPLOC/q/bzcUIKrQIa8erU3lwR3QaRqvaZK6VcmYa7m8svKeerLYdZtDGVhOSjeHkIM4e1595RnWjSSH/9Srkr/et2Q8YY1u7L5pONqSzbdpiScjsdWjTm4Uu7clXvUFoF6Gl3lXJ3Gu5uZteRYzz6+TYSko/S1NeLSX3CmNw3jNjwZtr9olQDouHuJgpKK3hl+R7m/JJEgK8X/7yqF1f3CcXX29PZpSmlnEDD3cUZY/hm2xH+vnQHR46VMLV/OP93SVeaN/ZxdmlKKSfScHdhezPyefLLnazak0m3NgG8dkMf+rZr7uyylFL1gIa7C9qbUcCrPyay5Lc0Gvt48dgV3Zk+qB1eeupdpZSDhrsL2ZdZwL9/sELdz9uT24d14LahUXp9UqXUaTTcXUBiej6vrdjLkt/S8NVQV0rVgIZ7PXV8rPpbP+1nxe5M/H08mamhrpSqIQ33eqbcZuerLYeZvXo/Ow4fI6SJD/eP6cyNA9sRpCNglFI1pOFeTxhjWBCfwr9/SORwXgkdWzbhX5N6cWWsjlVXSp07Dfd6ICO/hIcWbWHF7kz6RTbnn1f1YnjnFnh46BGlSqnfR8Pdyb7dfoS/fraVwtIK/j6hB9MHtdPTBCilzpuGu5MUlFbwxNLtLExIpUfbAF6ZEkvHlnpOdaVU7dBwd4L4pBweWPgbqUeLuGtkB/40qjM+XnoAklKq9mi4X0A5hWU8s2wnCxNSCQ/yY+Htg4iLDHJ2WUopN6ThfgHY7YaPE1L41ze7KCip4Pbh7bn34k401otlKKXqiKZLHduelsejX2zj14O59I8K4h8Te9JZr1eqlKpjGu515GhhGa/8kMi8tUkENfbhxWtjuKp3qI6EUUpdEBrutay0wsZ7a5J49ce9FJZWcMOAdjx4SRcC/bydXZpSqgHRcK8lxhi+3HKYf32zi9SjxYzs0oK/XdaNTtoFo5RyAg33WrDp4FGeWLqDzSm5dG3dlPf/MICLOoU4uyylVANWo8HVIjJORHaLyF4RebiK+TeLSKaIbHbcbq39Uusfu93w6g+JTH5jDWnHZenlAAAW80lEQVS5xTw7OZqv7h2qwa6Ucrpqt9xFxBN4DRgDpALxIrLEGLPjlKYfG2PuroMa66WcwjL+/PFmVu3J5MrYtjx1VS+a6NBGVdtK8iD3IHj6QHBH8KhnJ5EzBoqPwrFDcCwNCjKgeTto1RP89RgOZ6pJGvUH9hpj9gOIyALgSuDUcG8wNh08yt0fbCKroIx/TOzJDQMidBSM+v3KiyF9Oxz+DbL3QW6yFei5yVa4H+ftb4Vmm2hoEwOtoyEoCjwbgVcjqOozaLdDeRGUFUJ5ofVcQKjV/pzrLIHUDXDgJ+s+N8UK9IriqtsHhEHrXv+7RQyCJi3O/X3V71KTcA8FUipNpwIDqmg3SUSGAXuAPxtjUqpoUztGjDj9uWuvhTvvhKIiuOyy0+fffLN1y8qCyZNPn3/HHXDddZCSAtOmnT7/gQcwV1zBu59v4J/r0mlTls+niUvo9Uu6Nf/RR2H0aNi8Ge677/TX//OfMHgwrFkDf/vb6fNffhliY2H5cvjHP06f/9//QpcusHQpvPDC6fPnz4fwcPj4Y3jjjdPnL1oEISEwd651O9XXX4O/P7z+OixcePr8lSut++efhy+/PHmenx8sW2Y9fvJJ+OGHk+cHB8Onn1qP//pXWLv25PlhYfD++9bj++6zfoaVde4Ms2eDrQLuugUSD4Ct0hZsbKz18wO48UZITQUPO7TIhbZZEFAKnUdBl3Hw3GeQXnDy8keNgvvvgP0r4c2HwT8fyr2gxMe6dekH190KgeFw3U3We5tKQXr8s5dzGG6eAP4ljlspGCCqO8T0B3sjmPsRVHhCo3JoUgRNi6FxGWC3lmUTKGn0v/cuaQtjJkF0d9ixCjYshaQE8LKf/jsSLyi3W7UZAU8beJrT2xmgzBuKHe8xfDx06gN79sNnS8EuYPew7j0MTBsF+TsgeR2Ycuv1BX5Q3AhKm8LkeyGiO8TvhAVLwK8UmhRDk0I4vAKafAvGUW++Hxxtat3ymljv8/XX4OMJr82C9UsgoAiaFoGnHWwe0LGr9cV2KB2OZEGpj7Wc/MZgmsGyb+r2s/efl+HoAfjHQ5B+0KrLw27dt20BFw+HoA7wxiJIOnbyZ3PQIHj6aevxpEmQnW09Pv73VIdqEu5VbZKe+olZCnxkjCkVkT8C7wEXn7YgkZnATICIiIhzLNW5SuzwwIe/8tXWLEbn7ueFfcsItJU6uyz35FcCbbKtgPCuAL898HQ4lB6D1kArrHA5HhKU/++13gXQ4RC0zgZvGxQ1AntnyNwFid9CNyDUH7IDrYAILATbfHjuBcBAMy845g9eNmiWb4Vw6VKYt9Ra/kWO96nwsP6IKzwh5zV4/mUoSIc+jvl2sd4boHg7rNsItjLoUmk9S72gwB8iRsHoqWBawJ0PcdqfXPMBEDse/PrC7N1WnX5l1pdDo3IYNQIiwyEtBX78zgpksILR7gFjLofO3SE5DRZ9Ao3KrNf7lkGzAtj9PuyeZ72mZxW/j637oHVPaDEKftgDeY2holJ09JxmbVhsK3V8MTWCowH/m7/gfSg/DJ++BEdXQVgmRGRYX2THGsO8SyFjO9jLoTNQ5vgdVHhZIdqklfXfhymxvjiC8iHs+JehB7x7GbTtDfZtEHHk5PD1OwyfzLC6s7x+gy5Z1s/XYH0BNs6D5bOs/34abYGwDBBjvY9fKQTsgn9+bL1XsONWmTkC63eDrRTCsW7FPlDoBwW+IDlV/EAvDDGmim/2yg1EBgGzjDGXOKb/CmCMefoM7T2BHGNM4NmWGxcXZxISEn5X0RdaYWkFt81LYO3+bB4a15Xbh7VvuN0wxbmQsgHSfoXmkdB+ODRtfeb2FWWQGg8HVltdAW17Q9tY8Gt+crvSAtjxBWyaDynrQDytrofGIVZbvyDHfXMoyoakn6w67OXg4Q1h/cDTGw6sAg8v6Ho5xN0CUcOt7gpjrIDf/TXsXgapCYCx3ie8P3QYBR0vhjaxJ/dr28qt/uTcFOu+ONfqKik9BiXHHxdYXR0tOkNIF+u+WbuTl2OMFVDFR61b45bQtFVt/mZ+P1u51VdeUWLdyh33x7tb2vap3f7zskJIXgP7frR+j77NILQPhPa1bgGhVXcxHWe3QdYe6zN4aJN1f2SrFbBg/U69/cHbz7p5eluvMTarm8rYrGl7hfWFW1FqfY4q8w+2tsaDOzju21u/00YB4ONvLd+nsbUvxBjIO2h1raXvsL6o0ndA9l6YugA6j629nx0gIhuNMXHVtqtBuHthdbWMAg4B8cD1xpjtldq0McYcdjy+CnjIGDPwbMt1lXDPKy5nxrsb2JySy/PXxHB1nzBnl3RhHTsMB9dA8lo4uNb6AJ/6j1uLblbItx8B7YZA/mHrD3ffCkj62errFY///WsOENTeCvo2sdYf6vbPoazA2mnYexrETK0+/MoK4eA6K9APrLaCNmYq9Jl+9i8csMIsY4cVXL4BZ2+r6j9bufV58Glshfm5stutoLeVWp/VRrVwfEp5ibUsr9q9PGathbtjYZcBLwOewBxjzFMi8gSQYIxZIiJPAxOACiAHuMMYs+tsy3SFcM8pLGPaO+vZk57Pv6f05tJebZxdUt0yxtraSF5jBXnyGmunHoB3YwjvBxGDIWKgtYWVs8/qp96/0gr/U3esBbWH9iOhw0iIHGqF++HNlba4NsOxVGsrqMfV0GcahA84+1abUg1crYZ7Xajv4Z5+rIQb317PwZwi3pzWl5FdWjq7JIvdBnmpVghn77O2VoPbW90BwR3B27fq1xXnQp5jdENJnuOWCyXHrMeFmVY3R1GW1d4/xArxiEHQbpA1MuNsW0QVpdbrk3+xtprbj7SGxFWnMAu8fKFRk3P/WSjVANU03HVgdhVSjxZxw9vrycovZe6M/gzqcOpelDpmjNWvnL33f7esRCvMc/b/r2/xVOJh9Qu26GIFbP4Rq684L8XqI66Kly/4Blp92Z3GOMJ8sPVFcS5b0F6NIGqodTsXjfWAL6Xqgob7KVJyirjuv2spKK3g/VsH0DuiefUvqg2l+bD2NUj8zgrzyuObPbytnZchnaDTaCt4gztZ974BVvvM3Vbf9fH7lA0Q0Nbaeo68CJqFW0P5AsOsIG8UYL3294x3VkrVexrulWQcK+HGd9ZTWGbjo5kD6dH2rAN+akdFGWycC6v+ZXWJRAyGnpOtIA/uaO2tD4wAz7P8qo4fJKKUUg4a7g65RWVMe2cDmfmlvH/rgLoPdrsddnwOPzxpHSARORRG/x3C+tbt+yqlGgQNd6CgtIKb3o3nQHYhc2/uR5/a7ooxBopyrCGCBUesnZrx71gjR1r2gBsWQcfROkpEKVVrGny4l5TbmDkvgW2H8njjhj4M7ngeO/jKiiBjJ6Rvc9y2w9Fk68jFUw+SCAyHiW9C9LX172RQSimX16DDvdxm556PfmXNvmxeui6GsT2qOfClKmmbIf4tOLjeGvd9/EAdnybQqoe1M7Npa2jaxjoop0lrazow/Oz96EopdR4abLrY7Yb/W7SF73ek88SVPbiq9zkceWq3WYewr3vdGtft08Q6OrPnJOscHK16QLNI8KjR6fKVUqrWNdhw/2B9Mp//eogHx3Zm+qDImr2oNB9+/QDWvwFHk6xRLGOfso6s9L0AI2uUUqqGGmS4p+QU8fSyXQzr3IK7Rnas/gXGwJaF8M1D1kmfwgdYI1u6XqFdK0qpeqnBJZMxhr9+thUBnr66V/Vnd8w7BF/+2TpdbFh/GPc0hFV75K9SSjlVgwv3hQkp/Lw3i39M7EloM78zNzQGNs2D7x61zjg37hnoP1NHtiilXEKDCvcjeSX848udDGwfxPX9z3KxkKNJsORe61SykUNhwr+tMxwqpZSLaDDhbozhkc+3Um63869J0Xh4VNEdY6uADf+FH5+yDii6/EXoO0NHvSilXE6DCffFm9P4YVcGj17ejXbBjU9vcHgLLLnHOmq04xi44kVo5lqXAlRKqeMaRLhn5pcya+l2ekc0Y8aQqJNnlhXBqmdgzX+sS4lNnmNdOEJPBaCUcmENItwfX7KNolIbz02OxrNyd8y+H62RMEeTrEuzjf577V4rUimlnMTtw/2nxEy+3nqEv1zShY4tK10XcfsX8MlN1ml1b/ry3C8yoZRS9Zjbh/ucnw8Q0qQRtw2tNNolKxEW3wVh/axgP9Ol6ZRSykW59TCQpKxCVu7J5PoBEfh4OVa1rBA+nmZdgeia9zTYlVJuya233OevS8ZThBsGOEa9GGP1sWfugmmfQWCocwtUSqk64rZb7oWlFSxMSOHSXm1oFeDYOk94B7Z8DCMfgQ4XO7dApZSqQ24b7p//eoj8kgpuHtzOeuLQRvjmr9BpLAx9wLnFKaVUHXPLcDfGMG9tEj3aBliXzCvKgYU3WRfKuOq/esSpUsrtuWXKrd2fzZ70Am4aHIkYA5/dZl3q7tr3dBy7UqpBqFG4i8g4EdktIntF5OGztJssIkZEnHpO3PfWJNHc35sJMW3ht49g73LrrI6hfZxZllJKXTDVhruIeAKvAZcC3YGpItK9inZNgXuB9bVd5LlIPVrE9zvSmdI/Al9P4KfnoXU0xN3izLKUUuqCqsmWe39grzFmvzGmDFgAXFlFuyeBZ4GSWqzvnL2/7iAANw5sB9s+g5z9MOwveq4YpVSDUpNwDwVSKk2nOp47QUR6A+HGmC/PtiARmSkiCSKSkJmZec7FVqek3MaC+IOM6d6K0IBG1lZ7i27W5fCUUqoBqUm4V7XJa07MFPEAXgKqHV9ojJltjIkzxsS1aNGi5lXW0JLf0sgtKuemwZGwc4l1sNKwB3V0jFKqwalJ6qUC4ZWmw4C0StNNgZ7AShFJAgYCSy70TlVjDO+tSaJLq6YMigqC1c9bJwXrcdWFLEMppeqFmoR7PNBJRKJExAeYAiw5PtMYk2eMCTHGRBpjIoF1wARjTEKdVHwGmw7msj3tGNMHt0MSv4X0rdbBSnrNU6VUA1RtuBtjKoC7gW+BncBCY8x2EXlCRCbUdYE1lZCUA8DlPVvDqmehWTvodY2Tq1JKKeeo0YnDjDFfA1+f8txjZ2g74vzLOndJ2YUENfah2eGfIG0TjH8FPL2dUYpSSjmd2+xpPJBVSGSQH6x6DgJCIWaqs0tSSimncatwH+WfCCnrYMh91vnalVKqgXKL87kXlVWQfqyUCX4fQJNW0Geas0tSSimncost96SsIvrIHsLz4mHwveDt5+ySlFLKqdwj3LMLucVrGTafAIib4exylFLK6dwi3DNT9zHOIx5b75vAp7Gzy1FKKadzi3AP2/cRIuAz8DZnl6KUUvWC64d7eTH9speQ0GggNG/n7GqUUqpecP1w37qIAHOMX9tOcXYlSilVb7j2UEhjsK19gz32CEzEEGdXo5RS9YZrb7kn/4Jn5nbetV1CVAvdkaqUUse5drivf5My70AW24YQGaLhrpRSx7luuOcehF1fsaXVVZTiQ7sgDXellDrOdfvc498GhK98L6dNoCd+PnredqWUOs41w72sEDa+B93G82tmYyKDNdiVUqoy1+yW2bIQSnJhwB9Jyi7UnalKKXUK1wt3Y2D9f6F1NLkhfcgtKicqWMNdKaUqc71wP7AaMnfCgD9yILsIQEfKKKXUKVwv3HP2QbMI6DmJpOxCAKJC/J1clFJK1S+ut0M17hboPR08vTiQWYiHQHiQhrtSSlXmelvuAJ7Wd9KB7CJCm/vRyEtHyyilVGWuGe4OSVmFROrOVKWUOo3LhrsxhqSsQqJ0Z6pSSp3GZcM9u7CM/NIK3XJXSqkquGy4J2UdHymj4a6UUqeqUbiLyDgR2S0ie0Xk4Srm/1FEtorIZhH5WUS6136pJ9vvCHcd466UUqerNtxFxBN4DbgU6A5MrSK8PzTG9DLGxALPAi/WeqWnSMoqxMtDCGvuV9dvpZRSLqcmW+79gb3GmP3GmDJgAXBl5QbGmGOVJhsDpvZKrFpSdiHhQf54e7psz5JSStWZmhzEFAqkVJpOBQac2khE7gLuB3yAi6takIjMBGYCREREnGutJzmQVURksB68pJRSVanJZq9U8dxpW+bGmNeMMR2Ah4BHq1qQMWa2MSbOGBPXokWLc6v05OWQnF2o/e1KKXUGNQn3VCC80nQYkHaW9guAiedTVHUy8kspKrPpSBmllDqDmoR7PNBJRKJExAeYAiyp3EBEOlWavBxIrL0ST7c/U4dBKqXU2VTb526MqRCRu4FvAU9gjjFmu4g8ASQYY5YAd4vIaKAcOArcVJdFHz8bpB7ApJRSVavRWSGNMV8DX5/y3GOVHv+plus6q6SsQnw8PWjbTIdBKqVUVVxyHOGBrEIigv3x9KhqX69SSimXDPekbD0bpFJKnY3LhbvdbkjKLtKrLyml1Fm4XLin5RVTVmEnKqSJs0tRSql6y+XCPSnr+EWxdctdKaXOxOXC/UC2jnFXSqnquFy4t2raiLHdW9Gqqa+zS1FKqXqrRuPc65OxPVoztkdrZ5ehlFL1msttuSullKqehrtSSrkhDXellHJDGu5KKeWGNNyVUsoNabgrpZQb0nBXSik3pOGulFJuSIw57VrXF+aNRTKB5N/58hAgqxbLcQW6zg2DrnPDcD7r3M4Y06K6Rk4L9/MhIgnGmDhn13Eh6To3DLrODcOFWGftllFKKTek4a6UUm7IVcN9trMLcAJd54ZB17lhqPN1dsk+d6WUUmfnqlvuSimlzkLDXSml3JDLhbuIjBOR3SKyV0QednY9dUFE5ohIhohsq/RckIh8LyKJjvvmzqyxNolIuIisEJGdIrJdRP7keN6d19lXRDaIyG+Odf674/koEVnvWOePRcTH2bXWNhHxFJFfReRLx7Rbr7OIJInIVhHZLCIJjufq/LPtUuEuIp7Aa8ClQHdgqoh0d25VdWIuMO6U5x4GfjDGdAJ+cEy7iwrgAWNMN2AgcJfj9+rO61wKXGyMiQFigXEiMhD4F/CSY52PAn9wYo115U/AzkrTDWGdRxpjYiuNba/zz7ZLhTvQH9hrjNlvjCkDFgBXOrmmWmeMWQ3knPL0lcB7jsfvARMvaFF1yBhz2BizyfE4H+sPPxT3XmdjjClwTHo7bga4GFjkeN6t1hlARMKAy4G3HdOCm6/zGdT5Z9vVwj0USKk0nep4riFoZYw5DFYYAi2dXE+dEJFIoDewHjdfZ0f3xGYgA/ge2AfkGmMqHE3c8fP9MvB/gN0xHYz7r7MBvhORjSIy0/FcnX+2Xe0C2VLFczqW002ISBPgU+A+Y8wxa6POfRljbECsiDQDPge6VdXswlZVd0TkCiDDGLNRREYcf7qKpm6zzg5DjDFpItIS+F5Edl2IN3W1LfdUILzSdBiQ5qRaLrR0EWkD4LjPcHI9tUpEvLGC/QNjzGeOp916nY8zxuQCK7H2NzQTkeMbXe72+R4CTBCRJKwu1YuxtuTdeZ0xxqQ57jOwvsT7cwE+264W7vFAJ8fedR9gCrDEyTVdKEuAmxyPbwIWO7GWWuXod30H2GmMebHSLHde5xaOLXZExA8YjbWvYQUw2dHMrdbZGPNXY0yYMSYS62/3R2PMDbjxOotIYxFpevwxMBbYxgX4bLvcEaoichnWt70nMMcY85STS6p1IvIRMALrtKDpwOPAF8BCIAI4CFxjjDl1p6tLEpGLgJ+ArfyvL/ZvWP3u7rrO0Vg70jyxNrIWGmOeEJH2WFu1QcCvwI3GmFLnVVo3HN0yDxpjrnDndXas2+eOSS/gQ2PMUyISTB1/tl0u3JVSSlXP1bpllFJK1YCGu1JKuSENd6WUckMa7kop5YY03JVSyg1puCullBvScFdKKTf0/wGnTFvuJHyD4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.hlines(y=loss_loadback, xmin=0, xmax=len(train_loss), colors='r', linestyles='--')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.hlines(y=acc_loadback, xmin=0, xmax=len(train_loss), colors='r', linestyles='--')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.2081 - acc: 0.2700 - val_loss: 2.0328 - val_acc: 0.3239\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.7459 - acc: 0.3917 - val_loss: 1.8020 - val_acc: 0.3772\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6208 - acc: 0.4317 - val_loss: 1.7253 - val_acc: 0.4008\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.5431 - acc: 0.4594 - val_loss: 1.6274 - val_acc: 0.4299\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.4881 - acc: 0.4789 - val_loss: 1.5938 - val_acc: 0.4352\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 1.4403 - acc: 0.4974 - val_loss: 1.5664 - val_acc: 0.4530\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.4006 - acc: 0.5117 - val_loss: 1.5474 - val_acc: 0.4559\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3674 - acc: 0.5228 - val_loss: 1.5248 - val_acc: 0.4609\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.3325 - acc: 0.5365 - val_loss: 1.5238 - val_acc: 0.4667\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.3029 - acc: 0.5459 - val_loss: 1.4992 - val_acc: 0.4759\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.2745 - acc: 0.5599 - val_loss: 1.4972 - val_acc: 0.4745\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2483 - acc: 0.5680 - val_loss: 1.4950 - val_acc: 0.4767\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.2245 - acc: 0.5762 - val_loss: 1.4760 - val_acc: 0.4840\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.1967 - acc: 0.5872 - val_loss: 1.4674 - val_acc: 0.4866\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.1727 - acc: 0.5978 - val_loss: 1.4768 - val_acc: 0.4819\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.1504 - acc: 0.6060 - val_loss: 1.4636 - val_acc: 0.4941\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.1254 - acc: 0.6158 - val_loss: 1.4611 - val_acc: 0.4898\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.1041 - acc: 0.6233 - val_loss: 1.4569 - val_acc: 0.4900\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0834 - acc: 0.6317 - val_loss: 1.4580 - val_acc: 0.4915\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0603 - acc: 0.6394 - val_loss: 1.4593 - val_acc: 0.4939\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0385 - acc: 0.6473 - val_loss: 1.4509 - val_acc: 0.4954\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0160 - acc: 0.6566 - val_loss: 1.4656 - val_acc: 0.4885\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9978 - acc: 0.6630 - val_loss: 1.4552 - val_acc: 0.4925\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.9756 - acc: 0.6725 - val_loss: 1.4597 - val_acc: 0.4931\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9528 - acc: 0.6823 - val_loss: 1.4663 - val_acc: 0.4957\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9337 - acc: 0.6882 - val_loss: 1.4635 - val_acc: 0.4945\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9138 - acc: 0.6974 - val_loss: 1.4829 - val_acc: 0.4935\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.8917 - acc: 0.7055 - val_loss: 1.4684 - val_acc: 0.4963\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8717 - acc: 0.7137 - val_loss: 1.4849 - val_acc: 0.4973\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8528 - acc: 0.7198 - val_loss: 1.4904 - val_acc: 0.4982\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8328 - acc: 0.7290 - val_loss: 1.4903 - val_acc: 0.4956\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8133 - acc: 0.7346 - val_loss: 1.4969 - val_acc: 0.4920\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.7919 - acc: 0.7434 - val_loss: 1.5073 - val_acc: 0.4924\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.7752 - acc: 0.7500 - val_loss: 1.5150 - val_acc: 0.4976\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.7554 - acc: 0.7583 - val_loss: 1.5437 - val_acc: 0.4839\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.7357 - acc: 0.7654 - val_loss: 1.5233 - val_acc: 0.4946\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.7182 - acc: 0.7731 - val_loss: 1.5471 - val_acc: 0.4980\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.6990 - acc: 0.7790 - val_loss: 1.5549 - val_acc: 0.4922\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.6781 - acc: 0.7889 - val_loss: 1.5654 - val_acc: 0.4913\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.6586 - acc: 0.7955 - val_loss: 1.5754 - val_acc: 0.4942\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.6435 - acc: 0.8014 - val_loss: 1.5698 - val_acc: 0.4963\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.6257 - acc: 0.8088 - val_loss: 1.5851 - val_acc: 0.4880\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.6075 - acc: 0.8170 - val_loss: 1.6096 - val_acc: 0.4940\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.5892 - acc: 0.8235 - val_loss: 1.6255 - val_acc: 0.4903\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.5720 - acc: 0.8308 - val_loss: 1.6320 - val_acc: 0.4911\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.5549 - acc: 0.8375 - val_loss: 1.6368 - val_acc: 0.4912\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.5371 - acc: 0.8446 - val_loss: 1.6709 - val_acc: 0.4844\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.5197 - acc: 0.8522 - val_loss: 1.6694 - val_acc: 0.4892\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.5025 - acc: 0.8580 - val_loss: 1.6749 - val_acc: 0.4868\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.4885 - acc: 0.8639 - val_loss: 1.6792 - val_acc: 0.4917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_nb = build_mlp(input_shape=x_train.shape[1:])\n",
    "model_nb.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model_nb.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model_nb.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[model_ckpt2]\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model_nb.history.history[\"loss\"]\n",
    "valid_loss = model_nb.history.history[\"val_loss\"]\n",
    "train_acc = model_nb.history.history[\"acc\"]\n",
    "valid_acc = model_nb.history.history[\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results\n",
    "train_loss = model_nb.history.history[\"loss\"]\n",
    "valid_loss = model_nb.history.history[\"val_loss\"]\n",
    "train_acc = model_nb.history.history[\"acc\"]\n",
    "valid_acc = model_nb.history.history[\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 175us/step\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.models.load_model(\"./tmp2.h5\")\n",
    "loss_loadback, acc_loadback = model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4508834177017211 0.4954\n"
     ]
    }
   ],
   "source": [
    "print(loss_loadback, acc_loadback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 70us/step\n",
      "1.4502722774505614 0.4997\n"
     ]
    }
   ],
   "source": [
    "# Load back\n",
    "model2 = keras.models.load_model(\"./tmp.h5\")\n",
    "loss_loadback, acc_loadback = model2.evaluate(x_test, y_test)\n",
    "print(loss_loadback, acc_loadback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "試比較 save_best_only 與否的差異 ==> better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "請僅存入將 save_weights_only 設定為 True, 並嘗試 reset ipynb 並將模型與權重重新建回並預測 x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt3 = ModelCheckpoint(filepath=\"./tmp3.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                 \n",
    "                             save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0724 00:04:13.352284 139620787275584 deprecation.py:323] From /home/jianhao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 2.2343 - acc: 0.2637 - val_loss: 2.1504 - val_acc: 0.3110\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.7367 - acc: 0.3937 - val_loss: 1.7807 - val_acc: 0.3880\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.6122 - acc: 0.4336 - val_loss: 1.6884 - val_acc: 0.4115\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5418 - acc: 0.4599 - val_loss: 1.6298 - val_acc: 0.4349\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4880 - acc: 0.4798 - val_loss: 1.5819 - val_acc: 0.4461\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.4436 - acc: 0.4975 - val_loss: 1.5580 - val_acc: 0.4495\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4029 - acc: 0.5111 - val_loss: 1.5400 - val_acc: 0.4568\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3687 - acc: 0.5221 - val_loss: 1.5138 - val_acc: 0.4670\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.3365 - acc: 0.5355 - val_loss: 1.5068 - val_acc: 0.4731\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3070 - acc: 0.5477 - val_loss: 1.4877 - val_acc: 0.4774\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.2791 - acc: 0.5556 - val_loss: 1.4797 - val_acc: 0.4801\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.2513 - acc: 0.5645 - val_loss: 1.4702 - val_acc: 0.4845\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.2262 - acc: 0.5760 - val_loss: 1.4687 - val_acc: 0.4844\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.2009 - acc: 0.5847 - val_loss: 1.4722 - val_acc: 0.4813\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1779 - acc: 0.5917 - val_loss: 1.4588 - val_acc: 0.4911\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.1550 - acc: 0.6015 - val_loss: 1.4557 - val_acc: 0.4890\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.1304 - acc: 0.6098 - val_loss: 1.4521 - val_acc: 0.4967\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.1092 - acc: 0.6203 - val_loss: 1.4565 - val_acc: 0.4919\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0884 - acc: 0.6276 - val_loss: 1.4464 - val_acc: 0.4956\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0661 - acc: 0.6354 - val_loss: 1.4486 - val_acc: 0.4972\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0429 - acc: 0.6443 - val_loss: 1.4432 - val_acc: 0.4976\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0217 - acc: 0.6541 - val_loss: 1.4521 - val_acc: 0.4985\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0017 - acc: 0.6607 - val_loss: 1.4542 - val_acc: 0.4985\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.9823 - acc: 0.6677 - val_loss: 1.4485 - val_acc: 0.4987\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9610 - acc: 0.6763 - val_loss: 1.4724 - val_acc: 0.4938\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9409 - acc: 0.6835 - val_loss: 1.4523 - val_acc: 0.5032\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9207 - acc: 0.6915 - val_loss: 1.4588 - val_acc: 0.5014\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9013 - acc: 0.7005 - val_loss: 1.4700 - val_acc: 0.5029\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.8826 - acc: 0.7074 - val_loss: 1.4583 - val_acc: 0.5025\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.8608 - acc: 0.7162 - val_loss: 1.4698 - val_acc: 0.5003\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.8408 - acc: 0.7240 - val_loss: 1.4708 - val_acc: 0.4983\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.8225 - acc: 0.7323 - val_loss: 1.4833 - val_acc: 0.5006\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.8014 - acc: 0.7406 - val_loss: 1.5044 - val_acc: 0.4894\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.7836 - acc: 0.7475 - val_loss: 1.4927 - val_acc: 0.5017\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.7631 - acc: 0.7540 - val_loss: 1.4959 - val_acc: 0.5002\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.7441 - acc: 0.7636 - val_loss: 1.5227 - val_acc: 0.5016\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.7262 - acc: 0.7686 - val_loss: 1.5442 - val_acc: 0.4971\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.7050 - acc: 0.7772 - val_loss: 1.5257 - val_acc: 0.4974\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.6884 - acc: 0.7835 - val_loss: 1.5488 - val_acc: 0.4910\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.6702 - acc: 0.7912 - val_loss: 1.5667 - val_acc: 0.4976\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.6496 - acc: 0.8019 - val_loss: 1.5571 - val_acc: 0.4939\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.6341 - acc: 0.8072 - val_loss: 1.5855 - val_acc: 0.4995\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.6170 - acc: 0.8123 - val_loss: 1.5799 - val_acc: 0.4945\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.5994 - acc: 0.8206 - val_loss: 1.6217 - val_acc: 0.4872\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.5813 - acc: 0.8277 - val_loss: 1.6117 - val_acc: 0.4887\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.5626 - acc: 0.8345 - val_loss: 1.6277 - val_acc: 0.4915\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.5451 - acc: 0.8418 - val_loss: 1.6379 - val_acc: 0.4977\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.5295 - acc: 0.8474 - val_loss: 1.6504 - val_acc: 0.4909\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.5131 - acc: 0.8539 - val_loss: 1.6791 - val_acc: 0.4850\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.4970 - acc: 0.8617 - val_loss: 1.6865 - val_acc: 0.4891\n"
     ]
    }
   ],
   "source": [
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[model_ckpt3]\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot create group in read only mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c2d64aafd669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./tmp3.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss_loadback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_loadback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_loadback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_loadback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot create group in read only mode.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot create group in read only mode."
     ]
    }
   ],
   "source": [
    "# Load back\n",
    "model6 = keras.models.load_model(\"./tmp3.h5\")\n",
    "loss_loadback, acc_loadback = model6.evaluate(x_test, y_test)\n",
    "print(loss_loadback, acc_loadback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = build_mlp(input_shape=x_train.shape[1:])\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 134us/step\n",
      "1.6864820539474488 0.4891\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model6.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "model6.load_weights(\"./tmp3.h5\")\n",
    "\n",
    "loss_loadback, acc_loadback = model6.evaluate(x_test, y_test)\n",
    "print(loss_loadback, acc_loadback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
